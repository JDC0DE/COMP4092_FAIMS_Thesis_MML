<!DOCTYPE html> <html lang=en style><!--
 Page saved with SingleFile 
 url: https://www.sciencedirect.com/science/article/pii/S1877050917316599 
 saved date: Sun Sep 18 2022 19:53:20 GMT+1000 (Australian Eastern Standard Time)
--><meta charset=utf-8>
<meta name=citation_pii content=S1877050917316599>
<meta name=citation_issn content=1877-0509>
<meta name=citation_volume content=112>
<meta name=citation_lastpage content=2056>
<meta name=citation_publisher content=Elsevier>
<meta name=citation_firstpage content=2048>
<meta name=citation_fulltext_world_readable content>
<meta name=citation_journal_title content="Procedia Computer Science">
<meta name=citation_type content=JOUR>
<meta name=citation_doi content=10.1016/j.procs.2017.08.250>
<meta name=dc.identifier content=10.1016/j.procs.2017.08.250>
<meta name=citation_article_type content="Full-length article">
<meta property=og:description content="Automatic classification of environmental sounds, such as dog barking and glass breaking, is becoming increasingly interesting, especially for mobile …">
<meta property=og:image content=https://ars.els-cdn.com/content/image/1-s2.0-S1877050917X00112-cov150h.gif>
<meta name=citation_title content="Classifying environmental sounds using image recognition networks">
<meta property=og:title content="Classifying environmental sounds using image recognition networks">
<meta name=citation_publication_date content=2017/01/01>
<meta name=citation_online_date content=2017/09/01>
<meta name=robots content=INDEX,FOLLOW,NOARCHIVE,NOODP,NOYDIR>
<title>Classifying environmental sounds using image recognition networks - ScienceDirect</title>
<link rel=canonical href=https://www.sciencedirect.com/science/article/pii/S1877050917316599>
<meta property=og:type content=article>
<meta name=viewport content="initial-scale=1">
<meta name=SDTech content="Proudly brought to you by the SD Technology team in London, Dayton, and Amsterdam">
<meta http-equiv=origin-trial content="A+cA2PUOfIOKAdSDJOW5CP9ZlxONy1yu+hqAq72zUtKw4rLdihqRp6Nui/jUyCyegr+BUtH+C+Elv0ufn05yBQEAAACFeyJvcmlnaW4iOiJodHRwczovL2RvdWJsZWNsaWNrLm5ldDo0NDMiLCJmZWF0dXJlIjoiUHJpdmFjeVNhbmRib3hBZHNBUElzIiwiZXhwaXJ5IjoxNjY5NzY2Mzk5LCJpc1N1YmRvbWFpbiI6dHJ1ZSwiaXNUaGlyZFBhcnR5Ijp0cnVlfQ=="><meta http-equiv=origin-trial content="A+zsdH3aNZT/bkjT8U/o5ACzyaeNYzTvtoVmwf/KOilfv39pxY2AIsOwhQJv+YnXp98i3TqrQibIVtMWs5UHjgoAAACLeyJvcmlnaW4iOiJodHRwczovL2dvb2dsZXN5bmRpY2F0aW9uLmNvbTo0NDMiLCJmZWF0dXJlIjoiUHJpdmFjeVNhbmRib3hBZHNBUElzIiwiZXhwaXJ5IjoxNjY5NzY2Mzk5LCJpc1N1YmRvbWFpbiI6dHJ1ZSwiaXNUaGlyZFBhcnR5Ijp0cnVlfQ=="><meta http-equiv=origin-trial content="AxceVEhIegcDEHqLXFQ2+vPKqzCppoJYsRCZ/BdfVnbM/sUUF2BXV8lwNosyYjvoxnTh2FC8cOlAnA5uULr/zAUAAACLeyJvcmlnaW4iOiJodHRwczovL2dvb2dsZXRhZ3NlcnZpY2VzLmNvbTo0NDMiLCJmZWF0dXJlIjoiUHJpdmFjeVNhbmRib3hBZHNBUElzIiwiZXhwaXJ5IjoxNjY5NzY2Mzk5LCJpc1N1YmRvbWFpbiI6dHJ1ZSwiaXNUaGlyZFBhcnR5Ijp0cnVlfQ=="><style>#gs-casa-r,#gs-casa-c,#gs-casa-b,#gs-casa-f,#gs-casa-h,#gs-casa-r::before,#gs-casa-c::before,#gs-casa-b::before,#gs-casa-f::before,#gs-casa-h::before,#gs-casa-r::after,#gs-casa-c::after,#gs-casa-b::after,#gs-casa-f::after,#gs-casa-h::after{background:transparent;border:0;box-sizing:content-box;content:normal;font-family:Arial,sans-serif;font-weight:normal;letter-spacing:normal;line-height:normal;margin:0;opacity:1;outline:none;overflow:visible;padding:0;pointer-events:auto;text-decoration:none;text-transform:none;transition:none;vertical-align:baseline;z-index:0}#gs-casa-r{height:0;position:absolute;right:0;top:0;width:0;z-index:2147483647}#gs-casa-c{bottom:100px;height:110px;overflow:hidden;pointer-events:none;position:fixed;right:0;width:116px}#gs-casa-b{animation:gs-casa-a-l-ent .225s cubic-bezier(.0,.0,.2,1) forwards;perspective:1px;position:absolute;right:0;text-align:center;top:20px;width:96px}#gs-casa-b::before,#gs-casa-b::after{border-radius:8px 0 0 8px;content:"";height:100%;left:0;perspective:1px;position:absolute;top:0;transform:translate3d(0,0,0);transition:opacity .2s;width:100%;z-index:-1}#gs-casa-b::before{box-shadow:0 0px 2px 0 rgba(0,0,0,.14),0 2px 2px 0 rgba(0,0,0,.12),0 4px 15px 0 rgba(0,0,0,.2);opacity:1}#gs-casa-b::after{box-shadow:0 8px 10px 1px rgba(0,0,0,.14),0 3px 14px 3px rgba(0,0,0,.12),0 4px 15px 0 rgba(0,0,0,.2);opacity:0}#gs-casa-b:active::before{opacity:0}#gs-casa-b:active::after{opacity:1}#gs-casa-f,#gs-casa-h{display:block;overflow:hidden;padding-left:4px}#gs-casa-f{background-color:#424242;border-radius:8px 0 0 0;color:#fff;font-size:18px;height:54px;line-height:54px;word-spacing:-2px}#gs-casa-h{background-color:#777;border-radius:0 0 0 8px;color:#e0e0e0;font-size:11px;height:16px;line-height:16px}@keyframes gs-casa-a-l-ent{0%{transform:translate3d(96px,0,0)}100%{transform:translate3d(0,0,0)}}@media (max-width:599px),(max-height:599px){#gs-casa-c{border-radius:6px 0 0 6px;bottom:30vh;height:96px;position:fixed;transform:translate(0,48px);width:92px}#gs-casa-b{width:72px}#gs-casa-f,#gs-casa-h{padding-left:3px}#gs-casa-f{border-radius:6px 0 0 0;font-size:14px;height:44px;line-height:44px}#gs-casa-h{border-radius:0 0 0 6px;font-size:9px;height:12px;line-height:12px}@keyframes gs-casa-a-l-ent{0%{transform:translate3d(72px,0,0)}100%{transform:translate3d(0,0,0)}}}#MathJax_Message{position:fixed;left:1em;bottom:1.5em;background-color:#E6E6E6;border:1px solid #959595;margin:0px;padding:2px 8px;z-index:102;color:black;font-size:80%;width:auto;white-space:nowrap}#\_pendo-badge\_9BcFvkCLLiElWp6hocDK3ZG6Z4E{top:auto!important;left:auto!important;bottom:0px!important;right:20px!important;position:fixed!important}.sf-hidden{display:none!important}</style><meta http-equiv=content-security-policy content="default-src 'none'; font-src 'self' data:; img-src 'self' data:; style-src 'unsafe-inline'; media-src 'self' data:; script-src 'unsafe-inline' data:;"></head>
<body><div id=MathJax_Message style=display:none></div>
<noscript>
      JavaScript is disabled on your browser.
      Please enable JavaScript to use all the features on this page.
      <img src=https://smetrics.elsevier.com/b/ss/elsevier-sd-prod/1/G.4--NS/1663494802461?pageName=sd%3Aproduct%3Ajournal%3Aarticle&c16=els%3Arp%3Ast&c2=sd&v185=img&v33=ae%3AANON_GUEST&c1=ae%3A228598&c12=ae%3A12975512 />
    </noscript>
<a class="sr-only sr-only-focusable" href=#screen-reader-main-content>Skip to main content</a>
<a class="sr-only sr-only-focusable" href=#screen-reader-main-title>Skip to article</a>
<!--[if lt IE 9]>
      <div id="ie8Warning" class="warning">
        <script>function ie8click() {
  const node = document.getElementById('ie8Warning');
  document.cookie = 'ie_warning_state=1';
  node.parentNode.removeChild(node);
}</script>
        <p>Please note that Internet Explorer version 8.x is not supported as of January 1, 2016.
        Please refer to <a href="https://service.elsevier.com/app/answers/detail/a_id/9831">this support page</a> for more information.</p>
        <a class="warning-close" onclick="ie8click()" title="Close IE warning">&times;</a>
      </div>
    <![endif]-->
<div data-iso-key=_0><div class=App id=app data-aa-name=root data-reactroot><div class=page><section><div class=sd-flex-container><div class=sd-flex-content><header id=gh-cnt><div id=gh-main-cnt class="u-flex-center-ver u-position-relative u-padding-s-hor u-padding-m-hor-from-sm u-padding-l-hor-from-lg"><a id=gh-branding class=u-flex-center-ver href=https://www.sciencedirect.com/ aria-label="ScienceDirect home page" data-aa-region=header data-aa-name=ScienceDirect><img class=gh-logo src=data:null;base64, alt="Elsevier logo" height=48 width=54><svg xmlns=http://www.w3.org/2000/svg role=img version=1.1 height=30 width=138 viewBox="0 0 138 30" class="gh-wordmark u-margin-s-left" fill=#f36d21 aria-labelledby=gh-wm-science-direct focusable=false aria-hidden=true alt="ScienceDirect Wordmark"><title id=gh-wm-science-direct>ScienceDirect</title><g><path class=a d=M4.23,21a9.79,9.79,0,0,1-4.06-.83l.29-2.08a7.17,7.17,0,0,0,3.72,1.09c2.13,0,3-1.22,3-2.39C7.22,13.85.3,13.43.3,9c0-2.37,1.56-4.29,5.2-4.29a9.12,9.12,0,0,1,3.77.75l-.1,2.08a7.58,7.58,0,0,0-3.67-1c-2.24,0-2.91,1.22-2.91,2.39,0,3,6.92,3.61,6.92,7.8C9.5,19.1,7.58,21,4.23,21Z></path><path class=a d=M20.66,20A6.83,6.83,0,0,1,16.76,21c-3,0-5.23-2.18-5.23-6.29,0-4.29,2.91-6.11,5.28-6.11,2.16,0,3.67.55,3.85,2.11,0,.23,0,.57,0,.86H18.81c0-1-.55-1.25-1.9-1.25a2.87,2.87,0,0,0-1.35.21c-.21.13-1.85.94-1.85,4.11s1.9,4.65,3.59,4.65a5.91,5.91,0,0,0,3.2-1.2Z></path><path class=a d=M23.75,6.9a1.45,1.45,0,0,1-1.3-1.46,1.32,1.32,0,1,1,2.63,0A1.5,1.5,0,0,1,23.75,6.9ZM22.76,9h2V20.74h-2Z></path><path class=a d=M29.55,14.6V15c0,2.81,1.38,4.34,3.85,4.34a6.37,6.37,0,0,0,3.69-1.22l.16,1.82A7.94,7.94,0,0,1,32.77,21c-3,0-5.3-2.29-5.3-6.16,0-4.06,2.21-6.24,5.25-6.24,3.61,0,4.73,1.87,4.73,6ZM35.63,13c-.08-2.29-1.09-2.7-3-2.7A3.78,3.78,0,0,0,31,10.7,3.7,3.7,0,0,0,29.76,13Z></path><path class=a d=M49.7,20.74h-2s.1-2.73.08-5.1c0,0,0-1.56,0-2.5-.05-1.79-.21-2.7-2-2.7a4.87,4.87,0,0,0-1.64.31,12.11,12.11,0,0,0-1.95,2.08v7.9h-2v-8.5a19.47,19.47,0,0,0-.1-2.34L39.95,9h1.85l.31,1.74a4.71,4.71,0,0,1,3.82-2.05c2.11,0,3.54.68,3.74,3.09.1,1.17.08,2.34.08,3.51C49.75,17.2,49.7,20.74,49.7,20.74Z></path><path class=a d=M61.5,20A6.83,6.83,0,0,1,57.6,21c-3,0-5.23-2.18-5.23-6.29,0-4.29,2.91-6.11,5.28-6.11,2.16,0,3.67.55,3.85,2.11,0,.23,0,.57,0,.86H59.66c0-1-.55-1.25-1.9-1.25a2.87,2.87,0,0,0-1.35.21c-.21.13-1.85.94-1.85,4.11s1.9,4.65,3.59,4.65a5.91,5.91,0,0,0,3.2-1.2Z></path><path class=a d=M64.75,14.6V15c0,2.81,1.38,4.34,3.85,4.34a6.37,6.37,0,0,0,3.69-1.22l.16,1.82A7.94,7.94,0,0,1,68,21c-3,0-5.3-2.29-5.3-6.16,0-4.06,2.21-6.24,5.25-6.24,3.61,0,4.73,1.87,4.73,6ZM70.84,13c-.08-2.29-1.09-2.7-3-2.7a3.78,3.78,0,0,0-1.56.36A3.7,3.7,0,0,0,65,13Z></path><path class=a d=M81.21,20.74H75.83V5h5.62c5.54,0,7.46,4.21,7.46,7.8C88.91,16.26,86.93,20.74,81.21,20.74Zm-.1-14H77.88V19.07h3c4,0,5.75-2.31,5.75-6.24C86.59,10.15,85.34,6.7,81.11,6.7Z></path><path class=a d=M92.86,6.9a1.45,1.45,0,0,1-1.3-1.46,1.32,1.32,0,1,1,2.63,0A1.5,1.5,0,0,1,92.86,6.9ZM91.87,9h2V20.74h-2Z></path><path class=a d=M104.48,10.83l-1.64.47c0-.18-.08-1-.83-1-1.14,0-2.08,1.9-2.5,2.91v7.49h-2V12.18a18.78,18.78,0,0,0-.1-2.29L97.3,9h1.85l.34,1.87a3.22,3.22,0,0,1,2.68-2.16,2,2,0,0,1,2.26,1.72c0,.18.05.29.05.31Z></path><path class=a d=M107.44,14.6V15c0,2.81,1.38,4.34,3.85,4.34A6.37,6.37,0,0,0,115,18.11l.16,1.82A7.94,7.94,0,0,1,110.67,21c-3,0-5.3-2.29-5.3-6.16,0-4.06,2.21-6.24,5.25-6.24,3.61,0,4.73,1.87,4.73,6ZM113.53,13c-.08-2.29-1.09-2.7-3-2.7a3.78,3.78,0,0,0-1.56.36A3.7,3.7,0,0,0,107.65,13Z></path><path class=a d=M126.24,20a6.83,6.83,0,0,1-3.9,1.09c-3,0-5.23-2.18-5.23-6.29,0-4.29,2.91-6.11,5.28-6.11,2.16,0,3.67.55,3.85,2.11,0,.23,0,.57,0,.86H124.4c0-1-.55-1.25-1.9-1.25a2.87,2.87,0,0,0-1.35.21c-.21.13-1.85.94-1.85,4.11s1.9,4.65,3.59,4.65a5.91,5.91,0,0,0,3.2-1.2Z></path><path class=a d=M134.51,20.45a7.36,7.36,0,0,1-2.7.62c-1.53,0-2.63-.86-2.63-2.94V10.52H127V9h2.13V5.81h2V9h3.09v1.56h-3.09v7c0,1.33.34,1.85,1.25,1.85a5.66,5.66,0,0,0,2-.55Z></path></g></svg></a><div class="gh-nav-cnt u-hide-from-print"><div class="gh-nav-links-container gh-nav-links-container-h u-hide-from-print gh-nav-content-container"><nav aria-label=links class="gh-nav gh-nav-links gh-nav-h"><ul class="gh-nav-list u-list-reset"><li class="gh-nav-item gh-move-to-spine"><a class="anchor gh-nav-action" href=https://www.sciencedirect.com/browse/journals-and-books data-aa-region=header data-aa-name="Journals &amp; Books"><span class=anchor-text>Journals &amp; Books</span></a></ul></nav><nav aria-label=utilities class="gh-nav gh-nav-utilities gh-nav-h"><ul class="gh-nav-list u-list-reset"><li class="gh-move-to-spine gh-help-button gh-help-icon"><div class=popover id=gh-help-icon-popover><div id=popover-trigger-gh-help-icon-popover><button class="button-link gh-nav-help-icon gh-icon-btn button-link-primary" aria-expanded=false aria-label="ScienceDirect Support Center links" type=button><svg focusable=false viewBox="0 0 114 128" aria-hidden=true alt="ScienceDirect help page" width=21.375 height=24 class="icon icon-help gh-icon"><path d="m57 8c-14.7 0-28.5 5.72-38.9 16.1-10.38 10.4-16.1 24.22-16.1 38.9 0 30.32 24.68 55 55 55 14.68 0 28.5-5.72 38.88-16.1 10.4-10.4 16.12-24.2 16.12-38.9 0-30.32-24.68-55-55-55zm0 1e1c24.82 0 45 20.18 45 45 0 12.02-4.68 23.32-13.18 31.82s-19.8 13.18-31.82 13.18c-24.82 0-45-20.18-45-45 0-12.02 4.68-23.32 13.18-31.82s19.8-13.18 31.82-13.18zm-0.14 14c-11.55 0.26-16.86 8.43-16.86 18v2h1e1v-2c0-4.22 2.22-9.66 8-9.24 5.5 0.4 6.32 5.14 5.78 8.14-1.1 6.16-11.78 9.5-11.78 20.5v6.6h1e1v-5.56c0-8.16 11.22-11.52 12-21.7 0.74-9.86-5.56-16.52-16-16.74-0.39-0.01-0.76-0.01-1.14 0zm-4.86 5e1v1e1h1e1v-1e1h-1e1z"></path></svg><span class=button-link-text></span></button></div></div><li class="gh-search-toggle gh-nav-item search-button-link"><a class="anchor button-link-primary gh-nav-action gh-icon-btn" href=https://www.sciencedirect.com/search data-aa-button=search-in-header-opened-from-article aria-label="Opens ScienceDirect Search"><span class=anchor-text></span><svg focusable=false viewBox="0 0 100 128" aria-hidden=true alt=Search width=18.75 height=24 class="icon icon-search gh-icon"><path d="m19.22 76.91c-5.84-5.84-9.05-13.6-9.05-21.85s3.21-16.01 9.05-21.85c5.84-5.83 13.59-9.05 21.85-9.05 8.25 0 16.01 3.22 21.84 9.05 5.84 5.84 9.05 13.6 9.05 21.85s-3.21 16.01-9.05 21.85c-5.83 5.83-13.59 9.05-21.84 9.05-8.26 0-16.01-3.22-21.85-9.05zm80.33 29.6l-26.32-26.32c5.61-7.15 8.68-15.9 8.68-25.13 0-10.91-4.25-21.17-11.96-28.88-7.72-7.71-17.97-11.96-28.88-11.96s-21.17 4.25-28.88 11.96c-7.72 7.71-11.97 17.97-11.97 28.88s4.25 21.17 11.97 28.88c7.71 7.71 17.97 11.96 28.88 11.96 9.23 0 17.98-3.07 25.13-8.68l26.32 26.32 7.03-7.03"></path></svg></a></ul></nav></div></div><div class="gh-profile-container gh-move-to-spine u-hide-from-print"><a class="link-button u-margin-m-left link-button-primary link-button-small" role=button href="https://www.sciencedirect.com/user/institution/login?targetURL=%2Fscience%2Farticle%2Fpii%2FS1877050917316599" id=gh-corpsignin-btn data-aa-region=header data-aa-name="Corporate sign in"><span class=link-button-text>Corporate sign in</span></a><a class="link-button u-margin-m-left link-button-secondary link-button-small" role=button href="https://www.sciencedirect.com/user/login?targetURL=%2Fscience%2Farticle%2Fpii%2FS1877050917316599&amp;from=globalheader" id=gh-signin-btn data-aa-region=header data-aa-name="Sign in"><span class=link-button-text>Sign in / register</span></a></div><div id=gh-mobile-menu class="mobile-menu u-hide-from-print sf-hidden"></div></div></header><div class=Article id=mathjax-container><div class=sticky-outer-wrapper><div class=sticky-inner-wrapper style=position:relative;z-index:2;transform:translate3d(0px,0px,0px)><div id=screen-reader-main-content></div><div class=accessbar role=region aria-label="Download options and search"><div class=accessbar-label></div><ul aria-label="PDF Options"><li><a class="link-button link-button-primary accessbar-primary-link" role=button aria-expanded=true aria-label="Download single PDF. Opens in a new window." aria-live=polite target=_blank href="https://www.sciencedirect.com/science/article/pii/S1877050917316599/pdf?md5=ebc69bd9b22743849a3a3f3730ad326a&amp;pid=1-s2.0-S1877050917316599-main.pdf" rel=nofollow><svg focusable=false viewBox="0 0 32 32" height=24 width=24 class="icon icon-pdf-multicolor pdf-icon"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke=#000 stroke-width=.703 fill=#fff></path><path d="M.167 2.592H22.39V9.72H.166z" stroke=#aaa stroke-width=.315 fill=#da0000></path><path fill=#fff9f9 d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill=#f91d0a></path></svg><span class=link-button-text>View&nbsp;<strong>PDF</strong></span></a><li><button class="button button-anchor accessbar-anchor-link" aria-label="Download Full Issue" type=button><span class=button-text>Download Full Issue</span></button></ul><form class=QuickSearch action=/search#submit aria-label=form><input type=search class=query aria-label="Search ScienceDirect" name=qs placeholder="Search ScienceDirect" value><button class="button button-primary" type=submit aria-label="Submit search"><span class=button-text><svg focusable=false viewBox="0 0 100 128" height=20 width=18.75 class="icon icon-search"><path d="m19.22 76.91c-5.84-5.84-9.05-13.6-9.05-21.85s3.21-16.01 9.05-21.85c5.84-5.83 13.59-9.05 21.85-9.05 8.25 0 16.01 3.22 21.84 9.05 5.84 5.84 9.05 13.6 9.05 21.85s-3.21 16.01-9.05 21.85c-5.83 5.83-13.59 9.05-21.84 9.05-8.26 0-16.01-3.22-21.85-9.05zm80.33 29.6l-26.32-26.32c5.61-7.15 8.68-15.9 8.68-25.13 0-10.91-4.25-21.17-11.96-28.88-7.72-7.71-17.97-11.96-28.88-11.96s-21.17 4.25-28.88 11.96c-7.72 7.71-11.97 17.97-11.97 28.88s4.25 21.17 11.97 28.88c7.71 7.71 17.97 11.96 28.88 11.96 9.23 0 17.98-3.07 25.13-8.68l26.32 26.32 7.03-7.03"></path></svg></span></button></form></div></div></div><div class="article-wrapper u-padding-s-top grid row"><div class="u-show-from-lg col-lg-6"><div class="TableOfContents u-margin-l-bottom" lang=en><div class=Outline id=toc-outline><h2 class=u-h4>Outline</h2><ol class=u-padding-xs-bottom><li><a href=#abs0001 data-aa-button="sd:product:journal:article:type=anchor:name=outlinelink" title=Abstract>Abstract</a><li><a href=#keys0001 data-aa-button="sd:product:journal:article:type=anchor:name=outlinelink" title=Keywords>Keywords</a><li><a href=#cebibsec1 data-aa-button="sd:product:journal:article:type=anchor:name=outlinelink" title=References>References</a></ol><div class=PageDivider></div></div><div class=CitedBy id=toc-cited-by><h2 class=u-h4><a href=#section-cited-by>Cited By (169)</a></h2><div class=PageDivider></div></div></div></div><article class="col-lg-12 col-md-16 pad-left pad-right" role=main lang=en><div class=Publication id=publication><div class="publication-brand u-show-from-sm"><a title="Go to Procedia Computer Science on ScienceDirect" href=https://www.sciencedirect.com/journal/procedia-computer-science><img class=publication-brand-image src=data:null;base64, alt=Elsevier></a></div><div class="publication-volume u-text-center"><h2 class="publication-title u-h3" id=publication-title><a class=publication-title-link title="Go to Procedia Computer Science on ScienceDirect" href=https://www.sciencedirect.com/journal/procedia-computer-science>Procedia Computer Science</a></h2><div class=text-xs><a title="Go to table of contents for this volume/issue" href=https://www.sciencedirect.com/journal/procedia-computer-science/vol/112/suppl/C>Volume 112</a>, 2017, Pages 2048-2056</div></div><div class="publication-cover u-show-from-sm"><a href=https://www.sciencedirect.com/journal/procedia-computer-science/vol/112/suppl/C><img class=publication-cover-image src="data:image/gif;base64,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" alt="Procedia Computer Science"></a></div></div><h1 id=screen-reader-main-title class="Head u-font-serif u-h2 u-margin-s-ver"><span class=title-text>Classifying environmental sounds using image recognition networks</span></h1><div class=Banner id=banner><div class="wrapper truncated"><div class="AuthorGroups text-xs"><div class=author-group id=author-group><span class=sr-only>Author links open overlay panel</span><a class="author size-m workspace-trigger" name=bau0659 href=https://www.sciencedirect.com/science/article/pii/S1877050917316599#!><span class=content><span class="text given-name">Venkatesh</span><span class="text surname">Boddapati</span><span class=author-ref id=baff0001><sup>a</sup></span></span></a><a class="author size-m workspace-trigger" name=bau0660 href=https://www.sciencedirect.com/science/article/pii/S1877050917316599#!><span class=content><span class="text given-name">Andrej</span><span class="text surname">Petef</span><span class=author-ref id=baff0002><sup>b</sup></span></span></a><a class="author size-m workspace-trigger" name=bau0661 href=https://www.sciencedirect.com/science/article/pii/S1877050917316599#!><span class=content><span class="text given-name">Jim</span><span class="text surname">Rasmusson</span><span class=author-ref id=baff0002><sup>b</sup></span></span></a><a class="author size-m workspace-trigger" name=bau0662 href=https://www.sciencedirect.com/science/article/pii/S1877050917316599#!><span class=content><span class="text given-name">Lars</span><span class="text surname">Lundberg</span><span class=author-ref id=baff0001><sup>a</sup></span><svg focusable=false viewBox="0 0 102 128" width=19.125 height=24 class="icon icon-envelope"><path d="m55.8 57.2c-1.78 1.31-5.14 1.31-6.9 0l-31.32-23.2h69.54l-31.32 23.19zm-55.8-24.78l42.94 32.62c2.64 1.95 6.02 2.93 9.4 2.93s6.78-0.98 9.42-2.93l40.24-30.7v-10.34h-102zm92 56.48l-18.06-22.74-8.04 5.95 17.38 21.89h-64.54l18.38-23.12-8.04-5.96-19.08 24.02v-37.58l-1e1 -8.46v61.1h102v-59.18l-1e1 8.46v35.62"></path></svg></span></a></div></div></div><button id=show-more-btn class="button show-hide-details button-primary" type=button data-aa-button=icon-expand><span class=button-text>Show more</span><svg focusable=false viewBox="0 0 92 128" height=20 width=17.25 class="icon icon-navigate-down"><path d="m1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button><div class="banner-options u-padding-xs-bottom"><button class="button toc-button button-anchor u-hide-from-lg u-margin-s-right sf-hidden" type=button><svg focusable=false viewBox="0 0 104 128" width=19.5 height=24 class="icon icon-list"><path d="m2e1 95a9 9 0 0 1 -9 9 9 9 0 0 1 -9 -9 9 9 0 0 1 9 -9 9 9 0 0 1 9 9zm0-3e1a9 9 0 0 1 -9 9 9 9 0 0 1 -9 -9 9 9 0 0 1 9 -9 9 9 0 0 1 9 9zm0-3e1a9 9 0 0 1 -9 9 9 9 0 0 1 -9 -9 9 9 0 0 1 9 -9 9 9 0 0 1 9 9zm14 55h68v1e1h-68zm0-3e1h68v1e1h-68zm0-3e1h68v1e1h-68z"></path></svg></button><button class="button-link AddToMendeley button show-on-desktop button-link-primary" type=button><svg focusable=false viewBox="0 0 86 128" height=16 width=16 class="icon icon-plus"><path d="m48 58v-38h-1e1v38h-38v1e1h38v38h1e1v-38h38v-1e1z"></path></svg><span class=button-link-text>Add to Mendeley</span></button><div class="Social u-display-inline-block" id=social><div class="popover social-popover" id=social-popover><div id=popover-trigger-social-popover><button class="button button-anchor" aria-expanded=false aria-haspopup=true type=button><svg focusable=false viewBox="0 0 128 128" height=16 width=16 class="icon icon-share"><path d="m9e1 112c-6.62 0-12-5.38-12-12s5.38-12 12-12 12 5.38 12 12-5.38 12-12 12zm-66-36c-6.62 0-12-5.38-12-12s5.38-12 12-12 12 5.38 12 12-5.38 12-12 12zm66-6e1c6.62 0 12 5.38 12 12s-5.38 12-12 12-12-5.38-12-12 5.38-12 12-12zm0 62c-6.56 0-12.44 2.9-16.48 7.48l-28.42-15.28c0.58-1.98 0.9-4.04 0.9-6.2s-0.32-4.22-0.9-6.2l28.42-15.28c4.04 4.58 9.92 7.48 16.48 7.48 12.14 0 22-9.86 22-22s-9.86-22-22-22-22 9.86-22 22c0 1.98 0.28 3.9 0.78 5.72l-28.64 15.38c-4.02-4.34-9.76-7.1-16.14-7.1-12.14 0-22 9.86-22 22s9.86 22 22 22c6.38 0 12.12-2.76 16.14-7.12l28.64 15.38c-0.5 1.84-0.78 3.76-0.78 5.74 0 12.14 9.86 22 22 22s22-9.86 22-22-9.86-22-22-22z"></path></svg><span class=button-text>Share</span></button></div></div></div><div class="ExportCitation u-display-inline-block" id=export-citation><div class="popover export-citation-popover" id=export-citation-popover><div id=popover-trigger-export-citation-popover><button class="button button-anchor" aria-expanded=false aria-haspopup=true type=button><svg focusable=false viewBox="0 0 106 128" height=16 width=16 class="icon icon-cited-by-66"><path xmlns=http://www.w3.org/2000/svg d="m2 58.78v47.22h44v-42h-34v-5.22c0-18.5 17.08-26.78 34-26.78v-1e1c-25.9 0-44 15.12-44 36.78zm1e2 -26.78v-1e1c-25.9 0-44 15.12-44 36.78v47.22h44v-42h-34v-5.22c0-18.5 17.08-26.78 34-26.78z"></path></svg><span class=button-text>Cite</span></button></div></div></div></div></div><div class=ArticleIdentifierLinks id=article-identifier-links><a class=doi href=https://doi.org/10.1016/j.procs.2017.08.250 target=_blank rel="noreferrer noopener" aria-label="Persistent link using digital object identifier" title="Persistent link using digital object identifier">https://doi.org/10.1016/j.procs.2017.08.250</a><a class=rights-and-content target=_blank rel="noreferrer noopener" href="https://s100.copyright.com/AppDispatchServlet?publisherName=ELS&amp;contentID=S1877050917316599&amp;orderBeanReset=true">Get rights and content</a></div><div class=LicenseInfo><div class=License><span>Under a Creative Commons </span><a target=_blank rel="noreferrer noopener" href=https://creativecommons.org/licenses/by-nc-nd/4.0/>license</a></div><div class=OpenAccessLabel><span class=access-indicator></span>Open access</div></div><section class=ReferencedArticles></section><section class=ReferencedArticles></section><div class=PageDivider></div><div class="Abstracts u-font-serif" id=abstracts><div class="abstract author" id=abs0001><h2 class="section-title u-h3 u-margin-l-top u-margin-xs-bottom">Abstract</h2><div id=abss0001><p id=spara0246>Automatic classification of environmental sounds, such as dog barking and glass breaking, is becoming increasingly interesting, especially for mobile devices. Most mobile devices contain both cameras and microphones, and companies that develop mobile devices would like to provide functionality for classifying both videos/images and sounds. In order to reduce the development costs one would like to use the same technology for both of these classification tasks. One way of achieving this is to represent environmental sounds as images, and use an image classification neural network when classifying images as well as sounds. In this paper we consider the classification accuracy for different image representations (Spectrogram, MFCC, and CRP) of environmental sounds. We evaluate the accuracy for environmental sounds in three publicly available datasets, using two well-known convolutional deep neural networks for image recognition (AlexNet and GoogLeNet). Our experiments show that we obtain good classification accuracy for the three datasets.</p></div></div></div><ul id=issue-navigation class="issue-navigation u-margin-s-bottom u-bg-grey1"><li class="previous move-left u-padding-s-ver u-padding-s-left"><a class="button-alternative button-alternative-tertiary" href=https://www.sciencedirect.com/science/article/pii/S1877050917316538><svg focusable=false viewBox="0 0 54 128" width=32 height=32 class="icon icon-navigate-left"><path d="m1 61l45-45 7 7-38 38 38 38-7 7z"></path></svg><span class=button-alternative-text><strong>Previous </strong><span class=extra-detail-1>article</span><span class=extra-detail-2> in issue</span></span></a><li class="next move-right u-padding-s-ver u-padding-s-right"><a class="button-alternative button-alternative-tertiary" href=https://www.sciencedirect.com/science/article/pii/S1877050917316629><span class=button-alternative-text><strong>Next </strong><span class=extra-detail-1>article</span><span class=extra-detail-2> in issue</span></span><svg focusable=false viewBox="0 0 54 128" width=32 height=32 class="icon icon-navigate-right"><path d="m1 99l38-38-38-38 7-7 45 45-45 45z"></path></svg></a></ul><div class="Keywords u-font-serif"><div id=keys0001 class=keywords-section><h2 class="section-title u-h3 u-margin-l-top u-margin-xs-bottom">Keywords</h2><div id=key1006 class=keyword><span id=cetext1006>Deep Learning</span></div><div id=key1007 class=keyword><span id=cetext1007>Convolutional Neural Networks</span></div><div id=key1008 class=keyword><span id=cetext1008>Environmental Sound Classification</span></div><div id=key1009 class=keyword><span id=cetext1009>Image Classification</span></div><div id=key1010 class=keyword><span id=cetext1010>GPU Processing</span></div></div></div><div class=PdfEmbed role=region aria-label="PDF viewer"><div class=u-margin-s-ver><a class=anchor href="https://www.sciencedirect.com/science/article/pii/S1877050917316599/pdf?md5=ebc69bd9b22743849a3a3f3730ad326a&amp;pid=1-s2.0-S1877050917316599-main.pdf" target=_blank><svg focusable=false viewBox="0 0 32 32" width=24 height=24 class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke=#000 stroke-width=.703 fill=#fff></path><path d="M.167 2.592H22.39V9.72H.166z" stroke=#aaa stroke-width=.315 fill=#da0000></path><path fill=#fff9f9 d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill=#f91d0a></path></svg><span class=anchor-text>Download full text in PDF</span></a></div></div><div class="related-content-links u-hide-from-md sf-hidden"></div><div class=Tail></div><section class="bibliography u-font-serif text-s" id=cebibsec1><h2 class="section-title u-h3 u-margin-l-top u-margin-xs-bottom">References</h2><section class=bibliography-sec id=cebibsec2><dl class=references id=reference-links-cebibsec2><dt class=label><a href=#bbib0001 id=ref-id-bib0001 data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name">1</a><dd class=reference id=oref0001><span>H. Zhang, I. McLoughlin, and Y. Song, “Robust sound event recognition using convolutional neural networks,” in <em>Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, 2015 559-563.</span><div class="ReferenceLinks u-font-sans"><a class=link target=_blank rel="noopener noreferrer" href="https://scholar.google.com/scholar?q=H.%20Zhang,%20I.%20McLoughlin,%20and%20Y.%20Song,%20Robust%20sound%20event%20recognition%20using%20convolutional%20neural%20networks,%20in%20Proceedings%20of%20the%20IEEE%20International%20Conference%20on%20Acoustics,%20Speech%20and%20Signal%20Processing%20,%202015%20559-563.">Google Scholar</a></div><dt class=label><a href=#bbib0002 id=ref-id-bib0002 data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name">2</a><dd class=reference id=sbref0002><div class=contribution>J.-C. Wang, H.-P. Lee, J.-F. Wang, C.-B. Lin<div id=ref-id-sbref0002><strong class=title>Robust Environmental Sound Recognition for Home Automation</strong></div></div><div class=host>IEEE Transactions on Automation Science and Engineering, 5 (1) (2008), pp. 25-31</div><div class=comment>Jan</div><div class="ReferenceLinks u-font-sans"><a class=link target=_blank rel="noopener noreferrer" href="https://scholar.google.com/scholar_lookup?title=Robust%20Environmental%20Sound%20Recognition%20for%20Home%20Automation&amp;publication_year=2008&amp;author=J.-C.%20Wang&amp;author=H.-P.%20Lee&amp;author=J.-F.%20Wang&amp;author=C.-B.%20Lin" aria-describedby=ref-id-sbref0002>Google Scholar</a></div><dt class=label><a href=#bbib0003 id=ref-id-bib0003 data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name">3</a><dd class=reference id=oref0003><span>O. Gencoglu, T. Virtanen, and H. Huttunen, “Recognition of acoustic events using deep neural networks,” in <em>Signal Processing Conference (EUSIPCO), 2014 Proceedings of the 22nd European</em>, 2014 506-510.</span><div class="ReferenceLinks u-font-sans"><a class=link target=_blank rel="noopener noreferrer" href="https://scholar.google.com/scholar?q=O.%20Gencoglu,%20T.%20Virtanen,%20and%20H.%20Huttunen,%20Recognition%20of%20acoustic%20events%20using%20deep%20neural%20networks,%20in%20Signal%20Processing%20Conference%20,%202014%20Proceedings%20of%20the%2022nd%20European,%202014%20506-510.">Google Scholar</a></div><dt class=label><a href=#bbib0004 id=ref-id-bib0004 data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name">4</a><dd class=reference id=sbref0004><div class=contribution>D. Barchiesi, D. Giannoulis, D. Stowell, M.D. Plumbley<div id=ref-id-sbref0004><strong class=title>Acoustic Scene Classification: Classifying environments from the sounds they produce</strong></div></div><div class=host>IEEE Signal Processing Magazine, 32 (3) (2015), pp. 16-34</div><div class=comment>May</div><div class="ReferenceLinks u-font-sans"><div class="u-margin-m-right u-display-inline"><els-view-pdf-element doc-type=scopus doc-id=2-s2.0-85032751587 class=pending disabled><template shadowmode=open delegatesfocus><style>@keyframes es-spin{0%{transform:rotateZ(0deg)}100%{transform:rotateZ(360deg)}}:host{display:inline-block}.es-link{color:var(--es-color-theme,#007398);cursor:pointer;display:inline-block;font-family:inherit;font-size:inherit;text-decoration:none;transition:color var(--es-animation-hover,0.3s) ease,border-bottom-color var(--es-animation-hover,0.3s) ease}.es-link:active,.es-link:focus,.es-link:hover{color:var(--es-color-theme-2,#e9711c)}.es-link:active .text,.es-link:focus .text,.es-link:hover .text{border-bottom:2px solid var(--es-color-theme-2,#e9711c)}.es-link.disabled,.es-link.disabled:active,.es-link.disabled:focus,.es-link.disabled:hover{color:var(--es-color-disabled,#b9b9b9);cursor:not-allowed}.es-link.disabled .text,.es-link.disabled:active .text,.es-link.disabled:focus .text,.es-link.disabled:hover .text{border-bottom:0px;transition:all 0s ease 0s}.es-link.loading .icon{animation:3s linear 0s infinite normal none running es-spin}.es-link .icon,.es-link .text{display:inline-block;vertical-align:middle}.es-link .icon{fill:currentcolor;overflow:hidden}.es-link.icon-large .icon{height:1.5em;width:1.5em;margin-right:0.5em}.es-link.icon-small .icon{height:1em;width:1em;margin-right:0.3em}.es-link .text{border-bottom:2px solid transparent;transition:border-bottom-color var(--es-animation-hover,0.3s)}</style></template></els-view-pdf-element></div><a class=link target=_blank rel="noopener noreferrer" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-85032751587&amp;partnerID=10&amp;rel=R3.0.0" aria-describedby=ref-id-sbref0004>View Record in Scopus</a><a class=link target=_blank rel="noopener noreferrer" href="https://scholar.google.com/scholar_lookup?title=Acoustic%20Scene%20Classification%3A%20Classifying%20environments%20from%20the%20sounds%20they%20produce&amp;publication_year=2015&amp;author=D.%20Barchiesi&amp;author=D.%20Giannoulis&amp;author=D.%20Stowell&amp;author=M.D.%20Plumbley" aria-describedby=ref-id-sbref0004>Google Scholar</a></div><dt class=label><a href=#bbib0005 id=ref-id-bib0005 data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name">5</a><dd class=reference id=oref0005><span>S. Chachada and C.-C. Jay Kuo, “Environmental Sound Recognition: A Survey,” in <em>Proceedings of the 2013 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference</em>, 2013.</span><div class="ReferenceLinks u-font-sans"><a class=link target=_blank rel="noopener noreferrer" href="https://scholar.google.com/scholar?q=S.%20Chachada%20and%20C.-C.%20Jay%20Kuo,%20Environmental%20Sound%20Recognition:%20A%20Survey,%20in%20Proceedings%20of%20the%202013%20Asia-Pacific%20Signal%20and%20Information%20Processing%20Association%20Annual%20Summit%20and%20Conference,%202013.">Google Scholar</a></div><dt class=label><a href=#bbib0006 id=ref-id-bib0006 data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name">6</a><dd class=reference id=sbref0006><div class=contribution>I. McLoughlin, H. Zhang, Z. Xie, Y. Song, W. Xiao<div id=ref-id-sbref0006><strong class=title>Robust Sound Event Classification Using Deep Neural Networks</strong></div></div><div class=host>IEEE/ACM Transactions on Audio, Speech, and Language Processing, 23 (3) (2015), pp. 540-552</div><div class=comment>Mar</div><div class="ReferenceLinks u-font-sans"><div class="u-margin-m-right u-display-inline"><els-view-pdf-element doc-type=scopus doc-id=2-s2.0-84924047173 class=pending disabled><template shadowmode=open delegatesfocus><style>@keyframes es-spin{0%{transform:rotateZ(0deg)}100%{transform:rotateZ(360deg)}}:host{display:inline-block}.es-link{color:var(--es-color-theme,#007398);cursor:pointer;display:inline-block;font-family:inherit;font-size:inherit;text-decoration:none;transition:color var(--es-animation-hover,0.3s) ease,border-bottom-color var(--es-animation-hover,0.3s) ease}.es-link:active,.es-link:focus,.es-link:hover{color:var(--es-color-theme-2,#e9711c)}.es-link:active .text,.es-link:focus .text,.es-link:hover .text{border-bottom:2px solid var(--es-color-theme-2,#e9711c)}.es-link.disabled,.es-link.disabled:active,.es-link.disabled:focus,.es-link.disabled:hover{color:var(--es-color-disabled,#b9b9b9);cursor:not-allowed}.es-link.disabled .text,.es-link.disabled:active .text,.es-link.disabled:focus .text,.es-link.disabled:hover .text{border-bottom:0px;transition:all 0s ease 0s}.es-link.loading .icon{animation:3s linear 0s infinite normal none running es-spin}.es-link .icon,.es-link .text{display:inline-block;vertical-align:middle}.es-link .icon{fill:currentcolor;overflow:hidden}.es-link.icon-large .icon{height:1.5em;width:1.5em;margin-right:0.5em}.es-link.icon-small .icon{height:1em;width:1em;margin-right:0.3em}.es-link .text{border-bottom:2px solid transparent;transition:border-bottom-color var(--es-animation-hover,0.3s)}</style></template></els-view-pdf-element></div><a class=link target=_blank rel="noopener noreferrer" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-84924047173&amp;partnerID=10&amp;rel=R3.0.0" aria-describedby=ref-id-sbref0006>View Record in Scopus</a><a class=link target=_blank rel="noopener noreferrer" href="https://scholar.google.com/scholar_lookup?title=Robust%20Sound%20Event%20Classification%20Using%20Deep%20Neural%20Networks&amp;publication_year=2015&amp;author=I.%20McLoughlin&amp;author=H.%20Zhang&amp;author=Z.%20Xie&amp;author=Y.%20Song&amp;author=W.%20Xiao" aria-describedby=ref-id-sbref0006>Google Scholar</a></div><dt class=label><a href=#bbib0007 id=ref-id-bib0007 data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name">7</a><dd class=reference id=sbref0007><div class=contribution>J.-C. Wang, C.-H. Lin, B.-W. Chen, M.-K. Tsai<div id=ref-id-sbref0007><strong class=title>Gabor-Based Nonuniform Scale-Frequency Map for Environmental Sound Classification in Home Automation</strong></div></div><div class=host>IEEE Transactions on Automation Science and Engineering, 11 (2) (2014), pp. 607-613</div><div class=comment>Apr</div><div class="ReferenceLinks u-font-sans"><a class=link target=_blank rel="noopener noreferrer" href="https://scholar.google.com/scholar_lookup?title=Gabor-Based%20Nonuniform%20Scale-Frequency%20Map%20for%20Environmental%20Sound%20Classification%20in%20Home%20Automation&amp;publication_year=2014&amp;author=J.-C.%20Wang&amp;author=C.-H.%20Lin&amp;author=B.-W.%20Chen&amp;author=M.-K.%20Tsai" aria-describedby=ref-id-sbref0007>Google Scholar</a></div><dt class=label><a href=#bbib0008 id=ref-id-bib0008 data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name">8</a><dd class=reference id=sbref0008><div class=contribution>L. Lu, H.-J. Zhang, S.Z. Li<div id=ref-id-sbref0008><strong class=title>Content-based audio classification and segmentation by using support vector machines</strong></div></div><div class=host>Multimedia Systems, 8 (6) (2003), pp. 482-492</div><div class=comment>Apr</div><div class="ReferenceLinks u-font-sans"><div class="u-margin-m-right u-display-inline"><els-view-pdf-element doc-type=scopus doc-id=2-s2.0-0037708486 class=pending disabled><template shadowmode=open delegatesfocus><style>@keyframes es-spin{0%{transform:rotateZ(0deg)}100%{transform:rotateZ(360deg)}}:host{display:inline-block}.es-link{color:var(--es-color-theme,#007398);cursor:pointer;display:inline-block;font-family:inherit;font-size:inherit;text-decoration:none;transition:color var(--es-animation-hover,0.3s) ease,border-bottom-color var(--es-animation-hover,0.3s) ease}.es-link:active,.es-link:focus,.es-link:hover{color:var(--es-color-theme-2,#e9711c)}.es-link:active .text,.es-link:focus .text,.es-link:hover .text{border-bottom:2px solid var(--es-color-theme-2,#e9711c)}.es-link.disabled,.es-link.disabled:active,.es-link.disabled:focus,.es-link.disabled:hover{color:var(--es-color-disabled,#b9b9b9);cursor:not-allowed}.es-link.disabled .text,.es-link.disabled:active .text,.es-link.disabled:focus .text,.es-link.disabled:hover .text{border-bottom:0px;transition:all 0s ease 0s}.es-link.loading .icon{animation:3s linear 0s infinite normal none running es-spin}.es-link .icon,.es-link .text{display:inline-block;vertical-align:middle}.es-link .icon{fill:currentcolor;overflow:hidden}.es-link.icon-large .icon{height:1.5em;width:1.5em;margin-right:0.5em}.es-link.icon-small .icon{height:1em;width:1em;margin-right:0.3em}.es-link .text{border-bottom:2px solid transparent;transition:border-bottom-color var(--es-animation-hover,0.3s)}</style></template></els-view-pdf-element></div><a class=link target=_blank rel="noopener noreferrer" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-0037708486&amp;partnerID=10&amp;rel=R3.0.0" aria-describedby=ref-id-sbref0008>View Record in Scopus</a><a class=link target=_blank rel="noopener noreferrer" href="https://scholar.google.com/scholar_lookup?title=Content-based%20audio%20classification%20and%20segmentation%20by%20using%20support%20vector%20machines&amp;publication_year=2003&amp;author=L.%20Lu&amp;author=H.-J.%20Zhang&amp;author=S.Z.%20Li" aria-describedby=ref-id-sbref0008>Google Scholar</a></div><dt class=label><a href=#bbib0009 id=ref-id-bib0009 data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name">9</a><dd class=reference id=sbref0009><div class=contribution>M.M. Mostafa, N. Billor<div id=ref-id-sbref0009><strong class=title>Recognition of Western style musical genres using machine learning techniques</strong></div></div><div class=host>Expert Systems with Applications, 36 (8) (2009), pp. 11378-11389</div><div class=comment>Oct</div><div class="ReferenceLinks u-font-sans"><a class=link href=https://www.sciencedirect.com/science/article/pii/S0957417409002759 aria-describedby=ref-id-sbref0009>Article</a><a class="anchor pdf link" href="https://www.sciencedirect.com/science/article/pii/S0957417409002759/pdfft?md5=ba9231af6fd54e172b112d89b28b84b4&amp;pid=1-s2.0-S0957417409002759-main.pdf" target=_blank rel=nofollow><svg focusable=false viewBox="0 0 32 32" width=24 height=24 class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke=#000 stroke-width=.703 fill=#fff></path><path d="M.167 2.592H22.39V9.72H.166z" stroke=#aaa stroke-width=.315 fill=#da0000></path><path fill=#fff9f9 d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill=#f91d0a></path></svg><span class=anchor-text>Download PDF</span></a><a class=link target=_blank rel="noopener noreferrer" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-67349245920&amp;partnerID=10&amp;rel=R3.0.0" aria-describedby=ref-id-sbref0009>View Record in Scopus</a><a class=link target=_blank rel="noopener noreferrer" href="https://scholar.google.com/scholar_lookup?title=Recognition%20of%20Western%20style%20musical%20genres%20using%20machine%20learning%20techniques&amp;publication_year=2009&amp;author=M.M.%20Mostafa&amp;author=N.%20Billor" aria-describedby=ref-id-sbref0009>Google Scholar</a></div><dt class=label><a href=#bbib00010 id=ref-id-bib00010 data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name">10</a><dd class=reference id=oref00010><span>Z. Zhang and B. Schuller, “Semi-supervised learning helps in sound event classification,” in <em>Acoustics, Speech and Signal Processing (ICASSP), 2012 IEEE International Conference on</em>, 2012 333-336.</span><div class="ReferenceLinks u-font-sans"><a class=link target=_blank rel="noopener noreferrer" href="https://scholar.google.com/scholar?q=Z.%20Zhang%20and%20B.%20Schuller,%20Semi-supervised%20learning%20helps%20in%20sound%20event%20classification,%20in%20Acoustics,%20Speech%20and%20Signal%20Processing%20,%202012%20IEEE%20International%20Conference%20on,%202012%20333-336.">Google Scholar</a></div><dt class=label><a href=#bbib00011 id=ref-id-bib00011 data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name">11</a><dd class=reference id=oref00011><span>K. J. Piczak, “Environmental sound classification with convolutional neural networks,” in <em>Proceedings of the IEEE 25th International Workshop on Machine Learning for Signal Processing (MLSP)</em>, 2015 1-6.</span><div class="ReferenceLinks u-font-sans"><a class=link target=_blank rel="noopener noreferrer" href="https://scholar.google.com/scholar?q=K.%20J.%20Piczak,%20Environmental%20sound%20classification%20with%20convolutional%20neural%20networks,%20in%20Proceedings%20of%20the%20IEEE%2025th%20International%20Workshop%20on%20Machine%20Learning%20for%20Signal%20Processing%20,%202015%201-6.">Google Scholar</a></div><dt class=label><a href=#bbib00012 id=ref-id-bib00012 data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name">12</a><dd class=reference id=sbref00012><div class=contribution>S. Sigtia, A.M. Stark, S. Krstuloviv, M.D. Plumbley<div id=ref-id-sbref00012><strong class=title>Automatic environmental sound recognition: performance versus computational cost</strong></div></div><div class=host>IEEE/ACM Transactions on Audio, Speech and Language Processing (TASLP), 24 (11) (2016)</div><div class="ReferenceLinks u-font-sans"><a class=link target=_blank rel="noopener noreferrer" href="https://scholar.google.com/scholar_lookup?title=Automatic%20environmental%20sound%20recognition%3A%20performance%20versus%20computational%20cost&amp;publication_year=2016&amp;author=S.%20Sigtia&amp;author=A.M.%20Stark&amp;author=S.%20Krstuloviv&amp;author=M.D.%20Plumbley" aria-describedby=ref-id-sbref00012>Google Scholar</a></div><dt class=label><a href=#bbib00013 id=ref-id-bib00013 data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name">13</a><dd class=reference id=oref00013><span>K. Choi, G. Fazekas, M. Sandler, and K. Cho, “Convolutional Recurrent Neural Networks for Music Classification,” <em>arXiv preprint arXiv:1609.04243</em>, 2016.</span><div class="ReferenceLinks u-font-sans"><a class=link target=_blank rel="noopener noreferrer" href="https://scholar.google.com/scholar?q=K.%20Choi,%20G.%20Fazekas,%20M.%20Sandler,%20and%20K.%20Cho,%20Convolutional%20Recurrent%20Neural%20Networks%20for%20Music%20Classification,%20arXiv%20preprint%20arXiv:1609.04243,%202016.">Google Scholar</a></div><dt class=label><a href=#bbib00014 id=ref-id-bib00014 data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name">14</a><dd class=reference id=oref00014><span>A. Krizhevsky, I. Sutskever, and G. E. Hinton, “Imagenet classification with deep convolutional neural networks,” in <em>Advances in neural information processing systems</em>, 2012 pp. 1097-1105.</span><div class="ReferenceLinks u-font-sans"><a class=link target=_blank rel="noopener noreferrer" href="https://scholar.google.com/scholar?q=A.%20Krizhevsky,%20I.%20Sutskever,%20and%20G.%20E.%20Hinton,%20Imagenet%20classification%20with%20deep%20convolutional%20neural%20networks,%20in%20Advances%20in%20neural%20information%20processing%20systems,%202012%20pp.%201097-1105.">Google Scholar</a></div><dt class=label><a href=#bbib00015 id=ref-id-bib00015 data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name">15</a><dd class=reference id=oref00015><span>C. Szegedy et al., “Going deeper with convolutions,” in <em>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</em>, 2015 1-9.</span><div class="ReferenceLinks u-font-sans"><a class=link target=_blank rel="noopener noreferrer" href="https://scholar.google.com/scholar?q=C.%20Szegedy%20et%20al.,%20Going%20deeper%20with%20convolutions,%20in%20Proceedings%20of%20the%20IEEE%20Conference%20on%20Computer%20Vision%20and%20Pattern%20Recognition,%202015%201-9.">Google Scholar</a></div><dt class=label><a href=#bbib00016 id=ref-id-bib00016 data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name">16</a><dd class=reference id=oref00016><span>K. J. Piczak, “ESC: Dataset for environmental sound classification,” in <em>Proceedings of the ACM International Conference on Multimedia</em>. ACM, 2015.</span><div class="ReferenceLinks u-font-sans"><a class=link target=_blank rel="noopener noreferrer" href="https://scholar.google.com/scholar?q=K.%20J.%20Piczak,%20ESC:%20Dataset%20for%20environmental%20sound%20classification,%20in%20Proceedings%20of%20the%20ACM%20International%20Conference%20on%20Multimedia.%20ACM,%202015.">Google Scholar</a></div><dt class=label><a href=#bbib00017 id=ref-id-bib00017 data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name">17</a><dd class=reference id=oref00017><span>J. Salamon, C. Jacoby, and J. P. Bello, “A dataset and taxonomy for urban sound research,” in <em>Proceedings of the ACM International Conference on Multimedia</em>. ACM, 2014 1041-1044.</span><div class="ReferenceLinks u-font-sans"><a class=link target=_blank rel="noopener noreferrer" href="https://scholar.google.com/scholar?q=J.%20Salamon,%20C.%20Jacoby,%20and%20J.%20P.%20Bello,%20A%20dataset%20and%20taxonomy%20for%20urban%20sound%20research,%20in%20Proceedings%20of%20the%20ACM%20International%20Conference%20on%20Multimedia.%20ACM,%202014%201041-1044.">Google Scholar</a></div><dt class=label><a href=#bbib00018 id=ref-id-bib00018 data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name">18</a><dd class=reference id=oref00018><span>T. Park and T. Lee, “Musical instrument sound classification with deep convolutional neural network using feature fusion approach,” <em>arXiv preprint arXiv:1512.07370</em>, 2015.</span><div class="ReferenceLinks u-font-sans"><a class=link target=_blank rel="noopener noreferrer" href="https://scholar.google.com/scholar?q=T.%20Park%20and%20T.%20Lee,%20Musical%20instrument%20sound%20classification%20with%20deep%20convolutional%20neural%20network%20using%20feature%20fusion%20approach,%20arXiv%20preprint%20arXiv:1512.07370,%202015.">Google Scholar</a></div><dt class=label><a href=#bbib00019 id=ref-id-bib00019 data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name">19</a><dd class=reference id=oref00019><span>Z. Xu, J. Hu, and W. Deng, “Recurrent Convolutional Neural Network for Video Classification,” in <em>Proceedings of the IEEE International Conference on Multimedia and Expo (ICME)</em>, 2016.</span><div class="ReferenceLinks u-font-sans"><a class=link target=_blank rel="noopener noreferrer" href="https://scholar.google.com/scholar?q=Z.%20Xu,%20J.%20Hu,%20and%20W.%20Deng,%20Recurrent%20Convolutional%20Neural%20Network%20for%20Video%20Classification,%20in%20Proceedings%20of%20the%20IEEE%20International%20Conference%20on%20Multimedia%20and%20Expo%20,%202016.">Google Scholar</a></div><dt class=label><a href=#bbib00020 id=ref-id-bib00020 data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name">20</a><dd class=reference id=sbref00020><div class=contribution>E. Cakir, G. Parascandolo, T. Heittola, H. Huttunen, T. Virtanen<div id=ref-id-sbref00020><strong class=title>Convolutional recurrent neural networks for polyphonic sound event detection</strong></div></div><div class=host>IEEE/ACM Transactions on Audio, Speech and Language Processing (TASLP), 25 (1) (2017)</div><div class=comment>01/</div><div class="ReferenceLinks u-font-sans"><a class=link target=_blank rel="noopener noreferrer" href="https://scholar.google.com/scholar_lookup?title=Convolutional%20recurrent%20neural%20networks%20for%20polyphonic%20sound%20event%20detection&amp;publication_year=2017&amp;author=E.%20Cakir&amp;author=G.%20Parascandolo&amp;author=T.%20Heittola&amp;author=H.%20Huttunen&amp;author=T.%20Virtanen" aria-describedby=ref-id-sbref00020>Google Scholar</a></div><dt class=label><a href=#bbib00021 id=ref-id-bib00021 data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name">21</a><dd class=reference id=oref00021><span>M. Abadi et al., “Tensorflow: Large-scale machine learning on heterogeneous distributed systems,” <em>arXiv preprint arXiv:1603.04467</em>, 2016.</span><div class="ReferenceLinks u-font-sans"><a class=link target=_blank rel="noopener noreferrer" href="https://scholar.google.com/scholar?q=M.%20Abadi%20et%20al.,%20Tensorflow:%20Large-scale%20machine%20learning%20on%20heterogeneous%20distributed%20systems,%20arXiv%20preprint%20arXiv:1603.04467,%202016.">Google Scholar</a></div><dt class=label><a href=#bbib00022 id=ref-id-bib00022 data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name">22</a><dd class=reference id=oref00022><span>J. Salamon and J. P. Bello, “Deep convolutional neural networks and data augumentation for environmental sound classification,” <em>arXiv preprint arXiv:1608.04363</em>, 2016.</span><div class="ReferenceLinks u-font-sans"><a class=link target=_blank rel="noopener noreferrer" href="https://scholar.google.com/scholar?q=J.%20Salamon%20and%20J.%20P.%20Bello,%20Deep%20convolutional%20neural%20networks%20and%20data%20augumentation%20for%20environmental%20sound%20classification,%20arXiv%20preprint%20arXiv:1608.04363,%202016.">Google Scholar</a></div><dt class=label><a href=#bbib00023 id=ref-id-bib00023 data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name">23</a><dd class=reference id=oref00023><span>J. Ye, T. Kobayashi, and M. Murakawa, “Urban sound event classification based on local and global features aggregation,” <em>in Applied Acoustics, 117</em>, 2017 246-256.</span><div class="ReferenceLinks u-font-sans"><a class=link target=_blank rel="noopener noreferrer" href="https://scholar.google.com/scholar?q=J.%20Ye,%20T.%20Kobayashi,%20and%20M.%20Murakawa,%20Urban%20sound%20event%20classification%20based%20on%20local%20and%20global%20features%20aggregation,%20in%20Applied%20Acoustics,%20117,%202017%20246-256.">Google Scholar</a></div><dt class=label><a href=#bbib00024 id=ref-id-bib00024 data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name">24</a><dd class=reference id=oref00024><span>A. Pillos, K. Alghamidi, N. Alzamel, V. Pavlov, and S. Machanavajhala, “A real-time environmental sound recognition system for the Android OS,” in <em>Proceedings of Detection and Classification of Acoustic Scenes and Events</em>, September 2016, Budapest.</span><div class="ReferenceLinks u-font-sans"><a class=link target=_blank rel="noopener noreferrer" href="https://scholar.google.com/scholar?q=A.%20Pillos,%20K.%20Alghamidi,%20N.%20Alzamel,%20V.%20Pavlov,%20and%20S.%20Machanavajhala,%20A%20real-time%20environmental%20sound%20recognition%20system%20for%20the%20Android%20OS,%20in%20Proceedings%20of%20Detection%20and%20Classification%20of%20Acoustic%20Scenes%20and%20Events,%20September%202016,%20Budapest.">Google Scholar</a></div><dt class=label><a href=#bbib00025 id=ref-id-bib00025 data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name">25</a><dd class=reference id=oref00025><span>L. Hertel, H. Phan, and A. Mertins, “Comparing time and frequency domain for audio event recognition using deep learning,” in <em>Proceedings of the IEEE International Joint Conference on Neural Networks (IJCNN)</em>, July 2016, Vancouver, Canada.</span><div class="ReferenceLinks u-font-sans"><a class=link target=_blank rel="noopener noreferrer" href="https://scholar.google.com/scholar?q=L.%20Hertel,%20H.%20Phan,%20and%20A.%20Mertins,%20Comparing%20time%20and%20frequency%20domain%20for%20audio%20event%20recognition%20using%20deep%20learning,%20in%20Proceedings%20of%20the%20IEEE%20International%20Joint%20Conference%20on%20Neural%20Networks%20,%20July%202016,%20Vancouver,%20Canada.">Google Scholar</a></div></dl></section></section><div id=section-cited-by><section class="ListArticles preview"><div class=PageDivider></div><header id=citing-articles-header><h2 class="u-h3 u-margin-l-ver u-font-serif">Cited by (169)</h2></header><div aria-describedby=citing-articles-header><div class="citing-articles u-margin-l-bottom"><ul><li class=ListArticleItem><div class=sub-heading><a href=https://www.sciencedirect.com/science/article/pii/S2667305322000539 target=_self><h3 class="article-title ellipsis text-s" id=citing-articles-article0-title>Environmental Sound Classification: A descriptive review of the literature</h3></a><div class="article-source ellipsis">2022, Intelligent Systems with Applications</div></div><div class=buttons><button class="button-link button-link-secondary list-item-details-toggle" data-aa-button="sd:product:journal:article:location=citing-articles:type=view-details" aria-describedby=citing-articles-article0-title aria-controls=citing-articles-article0 aria-expanded=false type=button><span class=button-link-text>Show abstract</span><svg focusable=false viewBox="0 0 92 128" width=17.25 height=24 class="icon icon-navigate-down"><path d="m1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></div><div class="u-display-none sf-hidden" aria-hidden=true></div><li class=ListArticleItem><div class=sub-heading><a href=https://www.sciencedirect.com/science/article/pii/S0957417422004171 target=_self><h3 class="article-title ellipsis text-s" id=citing-articles-article1-title>Recognize the surrounding: Development and evaluation of convolutional deep networks using gammatone spectrograms and raw audio signals</h3></a><div class="article-source ellipsis">2022, Expert Systems with Applications</div></div><div class=buttons><button class="button-link button-link-secondary list-item-details-toggle" data-aa-button="sd:product:journal:article:location=citing-articles:type=view-details" aria-describedby=citing-articles-article1-title aria-controls=citing-articles-article1 aria-expanded=false type=button><span class=button-link-text>Show abstract</span><svg focusable=false viewBox="0 0 92 128" width=17.25 height=24 class="icon icon-navigate-down"><path d="m1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></div><div class="u-display-none sf-hidden" aria-hidden=true></div><li class=ListArticleItem><div class=sub-heading><a href=https://www.sciencedirect.com/science/article/pii/S0003682X22002717 target=_self><h3 class="article-title ellipsis text-s" id=citing-articles-article2-title>A new lateral geniculate nucleus pattern-based environmental sound classification using a new large sound dataset</h3></a><div class="article-source ellipsis">2022, Applied Acoustics</div></div><div class=buttons><button class="button-link button-link-secondary list-item-details-toggle" data-aa-button="sd:product:journal:article:location=citing-articles:type=view-details" aria-describedby=citing-articles-article2-title aria-controls=citing-articles-article2 aria-expanded=false type=button><span class=button-link-text>Show abstract</span><svg focusable=false viewBox="0 0 92 128" width=17.25 height=24 class="icon icon-navigate-down"><path d="m1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></div><div class="u-display-none sf-hidden" aria-hidden=true></div><li class=ListArticleItem><div class=sub-heading><a href=https://www.sciencedirect.com/science/article/pii/S0003682X22001918 target=_self><h3 class="article-title ellipsis text-s" id=citing-articles-article3-title>From environmental sound representation to robustness of 2D CNN models against adversarial attacks</h3></a><div class="article-source ellipsis">2022, Applied Acoustics</div></div><div class=buttons><button class="button-link button-link-secondary list-item-details-toggle" data-aa-button="sd:product:journal:article:location=citing-articles:type=view-details" aria-describedby=citing-articles-article3-title aria-controls=citing-articles-article3 aria-expanded=false type=button><span class=button-link-text>Show abstract</span><svg focusable=false viewBox="0 0 92 128" width=17.25 height=24 class="icon icon-navigate-down"><path d="m1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></div><div class="u-display-none sf-hidden" aria-hidden=true></div><li class=ListArticleItem><div class=sub-heading><a href=https://www.sciencedirect.com/science/article/pii/S0003682X22001876 target=_self><h3 class="article-title ellipsis text-s" id=citing-articles-article4-title>When sub-band features meet attention mechanism while knowledge distillation for sound classification</h3></a><div class="article-source ellipsis">2022, Applied Acoustics</div></div><div class=buttons><button class="button-link button-link-secondary list-item-details-toggle" data-aa-button="sd:product:journal:article:location=citing-articles:type=view-details" aria-describedby=citing-articles-article4-title aria-controls=citing-articles-article4 aria-expanded=false type=button><span class=button-link-text>Show abstract</span><svg focusable=false viewBox="0 0 92 128" width=17.25 height=24 class="icon icon-navigate-down"><path d="m1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></div><div class="u-display-none sf-hidden" aria-hidden=true></div><li class=ListArticleItem><div class=sub-heading><a href=https://www.sciencedirect.com/science/article/pii/S0925231222002922 target=_self><h3 class="article-title ellipsis text-s" id=citing-articles-article5-title>Data augmentation guided knowledge distillation for environmental sound classification</h3></a><div class="article-source ellipsis">2022, Neurocomputing</div></div><div class=buttons><button class="button-link button-link-secondary list-item-details-toggle" data-aa-button="sd:product:journal:article:location=citing-articles:type=view-details" aria-describedby=citing-articles-article5-title aria-controls=citing-articles-article5 aria-expanded=false type=button><span class=button-link-text>Show abstract</span><svg focusable=false viewBox="0 0 92 128" width=17.25 height=24 class="icon icon-navigate-down"><path d="m1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></div><div class="u-display-none sf-hidden" aria-hidden=true></div></ul><a class="button-alternative button-alternative-secondary button-cited-by-more" href="http://www.scopus.com/scopus/inward/citedby.url?partnerID=10&amp;rel=3.0.0&amp;eid=2-s2.0-85032359938&amp;md5=698682d60c0c182b43797ce8e3cb34" id=citing-articles-view-all-btn target=_blank><svg focusable=false viewBox="0 0 78 128" width=32 height=32 class="icon icon-arrow-up-right"><path d="m4 36h57.07l-59.5 59.5 7.07 7.08 59.36-59.36v56.78h1e1v-74h-74z"></path></svg><span class=button-alternative-text>View all citing articles on Scopus</span></a></div></div></section></div><div class=Copyright><span class=copyright-line>© 2017 The Authors. Published by Elsevier B.V.</span></div></article><div class="u-show-from-md col-lg-6 col-md-8 pad-right"><aside class=RelatedContent aria-label="Related content"><section class=SpecialIssueArticles id=special-issue-articles><div class="part-of-issue u-padding-s-bottom"><h2 class="part-of-issue-text u-h4">Part of special issue:</h2><div><a class=part-of-issue-title href=https://www.sciencedirect.com/science/journal/18770509/112/supp/C><span>Knowledge-Based and Intelligent Information &amp; Engineering Systems: Proceedings of the 21st International Conference, KES-20176-8 September 2017, Marseille, France</span></a><div class=part-of-issue-editors><span>Edited by </span><div class=authors><span>Cecilia</span> <span>Zanni-Merk</span>, <span>Claudia</span> <span>Frydman</span>, <span>Carlos</span> <span>Toro</span>, <span>Yulia</span> <span>Hicks</span>, <span>Robert J.</span> <span>Howlett</span>, <span>Lakhmi C.</span> <span>Jain</span></div></div></div><button class="button-alternative DownloadFullIssue button-alternative-primary" type=button id=download-full-issue><svg focusable=false viewBox="0 0 54 128" width=32 height=32 class="icon icon-navigate-right"><path d="m1 99l38-38-38-38 7-7 45 45-45 45z"></path></svg><span class=button-alternative-text>Download full issue</span></button></div><section class="SidePanel u-margin-s-bottom"><header id=special-issue-articles-header class="side-panel-header u-margin-s-bottom"><button class="button-link side-panel-toggle is-up button-link-primary" aria-expanded=true type=button><span class=button-link-text><h2 class="section-title u-h4">Other articles from this issue</h2></span><svg focusable=false viewBox="0 0 92 128" width=17.25 height=24 class="icon icon-navigate-down"><path d="m1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></header><div aria-hidden=false aria-describedby=special-issue-articles-header><div id=special-issue-articles><ul><li class=SidePanelItem><div class=sub-heading><a href=https://www.sciencedirect.com/science/article/pii/S1877050917313406><h3 class="article-title ellipsis text-s" id=special-issue-articles-article0-title><span>Maximization of Returns under an Average Value-at-Risk Constraint in Fuzzy Asset Management</span></h3></a><div class="article-source ellipsis">2017, pp. </div></div><div class=buttons><a class="anchor side-panel-pdf-link" href="https://www.sciencedirect.com/science/article/pii/S1877050917313406/pdfft?md5=ea66c20ee879dfc21203b2373d6aa746&amp;pid=1-s2.0-S1877050917313406-main.pdf" target=_blank rel=nofollow><svg focusable=false viewBox="0 0 32 32" width=24 height=24 class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke=#000 stroke-width=.703 fill=#fff></path><path d="M.167 2.592H22.39V9.72H.166z" stroke=#aaa stroke-width=.315 fill=#da0000></path><path fill=#fff9f9 d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill=#f91d0a></path></svg><span class=anchor-text>Download PDF</span></a><button class="button-link button-link-secondary side-panel-details-toggle move-right" data-aa-button=undefinedview-details aria-describedby=special-issue-articles-article0-title aria-controls=special-issue-articles-article0 aria-expanded=false type=button><span class=button-link-text>View details</span><svg focusable=false viewBox="0 0 92 128" width=17.25 height=24 class="icon icon-navigate-down"><path d="m1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></div><div id=special-issue-articles-article0 aria-hidden=true></div><li class=SidePanelItem><div class=sub-heading><a href=https://www.sciencedirect.com/science/article/pii/S1877050917313509><h3 class="article-title ellipsis text-s" id=special-issue-articles-article1-title><span>A Model for Multilingual Terminology Extraction via a Medical Social Network</span></h3></a><div class="article-source ellipsis">2017, pp. </div></div><div class=buttons><a class="anchor side-panel-pdf-link" href="https://www.sciencedirect.com/science/article/pii/S1877050917313509/pdfft?md5=d17f05776c98cb5bd7c2c5314b99edf4&amp;pid=1-s2.0-S1877050917313509-main.pdf" target=_blank rel=nofollow><svg focusable=false viewBox="0 0 32 32" width=24 height=24 class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke=#000 stroke-width=.703 fill=#fff></path><path d="M.167 2.592H22.39V9.72H.166z" stroke=#aaa stroke-width=.315 fill=#da0000></path><path fill=#fff9f9 d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill=#f91d0a></path></svg><span class=anchor-text>Download PDF</span></a><button class="button-link button-link-secondary side-panel-details-toggle move-right" data-aa-button=undefinedview-details aria-describedby=special-issue-articles-article1-title aria-controls=special-issue-articles-article1 aria-expanded=false type=button><span class=button-link-text>View details</span><svg focusable=false viewBox="0 0 92 128" width=17.25 height=24 class="icon icon-navigate-down"><path d="m1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></div><div id=special-issue-articles-article1 aria-hidden=true></div><li class=SidePanelItem><div class=sub-heading><a href=https://www.sciencedirect.com/science/article/pii/S1877050917313534><h3 class="article-title ellipsis text-s" id=special-issue-articles-article2-title><span>Logics and translations for hierarchical model checking</span></h3></a><div class="article-source ellipsis">2017, pp. </div></div><div class=buttons><a class="anchor side-panel-pdf-link" href="https://www.sciencedirect.com/science/article/pii/S1877050917313534/pdfft?md5=67b973105fde14e45c532040227530a6&amp;pid=1-s2.0-S1877050917313534-main.pdf" target=_blank rel=nofollow><svg focusable=false viewBox="0 0 32 32" width=24 height=24 class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke=#000 stroke-width=.703 fill=#fff></path><path d="M.167 2.592H22.39V9.72H.166z" stroke=#aaa stroke-width=.315 fill=#da0000></path><path fill=#fff9f9 d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill=#f91d0a></path></svg><span class=anchor-text>Download PDF</span></a><button class="button-link button-link-secondary side-panel-details-toggle move-right" data-aa-button=undefinedview-details aria-describedby=special-issue-articles-article2-title aria-controls=special-issue-articles-article2 aria-expanded=false type=button><span class=button-link-text>View details</span><svg focusable=false viewBox="0 0 92 128" width=17.25 height=24 class="icon icon-navigate-down"><path d="m1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></div><div id=special-issue-articles-article2 aria-hidden=true></div></ul><a class="anchor side-panel-view-more" href=https://www.sciencedirect.com/science/journal/18770509/112/supp/C target=_blank><span class=anchor-text>View more articles</span><svg focusable=false viewBox="0 0 54 128" width=10.125 height=24 class="icon icon-navigate-right"><path d="m1 99l38-38-38-38 7-7 45 45-45 45z"></path></svg></a></div></div></section></section><section class="SidePanel u-margin-s-bottom"><header id=recommended-articles-header class="side-panel-header u-margin-s-bottom"><button class="button-link side-panel-toggle button-link-primary" aria-expanded=false data-aa-button="sd:product:journal:article:location=recommended-articles:type=open" type=button><span class=button-link-text><h2 class="section-title u-h4">Recommended articles</h2></span><svg focusable=false viewBox="0 0 92 128" width=17.25 height=24 class="icon icon-navigate-down"><path d="m1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></header><div class="u-display-none sf-hidden" aria-hidden=true aria-describedby=recommended-articles-header></div></section><section class="SidePanel u-margin-s-bottom"><header id=metrics-header class="side-panel-header u-margin-s-bottom"><button class="button-link side-panel-toggle is-up button-link-primary" aria-expanded=true type=button><span class=button-link-text><h2 class="section-title u-h4">Article Metrics</h2></span><svg focusable=false viewBox="0 0 92 128" width=17.25 height=24 class="icon icon-navigate-down"><path d="m1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></header><div aria-hidden=false aria-describedby=metrics-header><div class=plum-sciencedirect-theme><div class=PlumX-Summary><div class="pps-container pps-container-vertical plx-no-print"><div class="pps-branding pps-branding-top sf-hidden"></div><div class=pps-cols><div class="pps-col plx-citation"><div class=plx-citation><div class=pps-title>Citations</div><ul><li class=plx-citation><span class=pps-label>Citation Indexes: </span><span class=pps-count>146</span><li class=plx-citation><span class=pps-label>Patent Family Citations: </span><span class=pps-count>1</span></ul></div></div><div class="pps-col plx-capture"><div class=plx-capture><div class=pps-title>Captures</div><ul><li class=plx-capture><span class=pps-label>Exports-Saves: </span><span class=pps-count>3</span><li class=plx-capture><span class=pps-label>Readers: </span><span class=pps-count>165</span></ul></div></div></div><div><div class="pps-branding pps-branding-bottom"><img alt="plumX logo" src=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAPIAAAA7CAYAAABBj9fYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAHYAAAB2ABR4RaUgAAABl0RVh0U29mdHdhcmUAd3d3Lmlua3NjYXBlLm9yZ5vuPBoAABDYSURBVHja7V17eBTVFb+2Kj6QahUFBXZ2koI11ie1QtHGtj6wUp/rzkyCUiwhu5sUqQh5gK6i1n4+qn6+aMWQ3Q3WIFIotvJhLcVnW0WK4hO0qKigQsUoQRLSc2Zn42aZ+5jZ2d2EvX+cbzfZmTuPe3/3vM8hXV1dpNAUbSX7zoyT8oYYuaEhTp5rjJMP4XMt0EqgRfD3A/B5fV2CfL833K8kSb2NCgvgOeQAAO9dANIvgLoEaX1DgtzU0EyOkxMoSVKBgVzfTEYBKN90AOB02gVgfrY+ThqAW4+umkP2kZMpSQI53yCOk8kAxg6XIF7U2EJ8cvIkScoSyIFW8s2prWR/N+c2JsipAMavXIJ4ieS+kiS5BDKIwYeCKNsIQFpQnyCvwGc7UCfQ60APATjD0SayH1cnnk8OA534XQpIkUM/CtdZCJ9tNr8/XXsX6ScnTZIkh0COtpL+AKBZQJ9xuSUCNEEmIremcuOk9dnu3LmwQVwOIvca2viNMTJSTpgkSQ6BDKAKAW1yKv4CWJfhBmDL1eNke8bxW+D4i4Gjz+aMu0BOliRJDoBMusheAJx7XOqwKTC/EI2Rw3sAOUHqMo5bUddEFPj8A2e8jplxMkJOliRJgkCO/p3sDWJuCwdYHwA9Yfp/E6QWvt+O+ivQlxnHPZUuZgO4V3cDPUFiqO/C98UCG8O1cqIkSRIEMlqhQZSejxFVyFFNXy0fZB0A6CcR0DNjxI8+XfjemnItgV57HY5tgTZlqV6BkVxmUAd//JUsnVuSJElpQI5GyTcAxKdhpFXqBwSmBbbPBEXqTgDu7xvmkyNmziMl8Pe9qAOjpbquhZxsHfM6fD+koYWcYVm9WeNtaXyIDJWTJEmSB+4nBCVw2lUOdORtQDOQC6OejBuCGUcdJ5sBxKpl9NrIGeMj3FjkBEmS5KEf2RKN7xUUt1P0dn2MXITng/h9LIZkmt/ZejFy6UeubiKD5ORIkpSjyK7GFnIKxjgLgLgNjrsbwDs8I6orbHMsiu7PAN2MVmw5KZIk5SlEEzisBsBbCvSJxUV3YFYSWqPrE2RStIkcbHfejDg5HlMRUWeuayYnyphpSZL2gDRGSZLsqHpI4KgaVRsZUrWfhVVdry7RfxzyV46YdsT4A10vdEL2CiuBQaES4+SQX/t5xK9fWqNo5WFf8LtVR447wKt7x1wAYFCng0RaiV4cNCR7+W7q4qQUGGYQGOeZ6YFXngweLgv0D/n148J+fRy8pNOqfJWDmQ87XD8s4tNHhRXjhGwmR5QiPu1CuNYEtwTPVomLKqRUnIqLzNUEq4FhrGtMHlZxjJfPDAAYw3wumDPv36UWdH2/JdpoGOP2kKKvg3XURaGOsN9YFvFr40XXTaRULwsr+m8ifmMDY9z2sGr8JaRo1ZGjLjvUdVZfghwDAHu1h+qYVEUHZzuf6IaFce7YLaajhZzhGsjmzqYYM8J+7Tl4CZszXspnQCtCqv67GsU4e4IyoTuZorZ0bL9qRVMmq8Z3rIU2JeQ3YhFVXwvn/BVe5kUBEvDcbwxjv86YRDf0JiyMu8NqULhiCSzQC1hjRhT9Sk83L78+j3U9nIccvMuPnI6HHBLOW+5iDrbAO72cNu4Uv34ErLFHXYwL69eY5XSjsyIi37CzGQHAl+Pv2cynVT3Hzh61GTmzI9EkohrnWi9nZ49F6Nd3wP8XASgD6cAVpalDAvubO7rf+BfunLhJ4P96MZDTCDiEL3iSBLIzIEdJ9BsRVbsZztmV1fsHTlpdMv7wnoxGC8Lzf5rduPr7KN47KJQxnJNUNNU1iJNxF1SPEaYGi7mfSiuGwEL7G+WhEzVDtSM9Udhxs/Drv4QxtyKXrlErvtf7gWxtZIo+WQJZDMgoFoM09ycP5+DllEgMG+sVWW8OX9OXyJyEy1ax8+zb0Q3ruBxWE9kPzn2LtUlMf4gcKaJr6Qgsu5eH+nAudFoU3VE8B9oO1w/3diCnCMB6jQSy0Ga92PP3rxov4lqB750ejw16efAsIc4ZJ89zkolWYz6DI24cJzdzXL3rmDpy1clV+8BDxCkPtzTXRqrkrq0/ZQLEr93YF4CMnCCiGOdLIDMkE78xO09z4SVtCZdUlnLjLOKkihdjUR8n04TjNmJkJLckVoJcRQUy6i8govzRXozU5uTCIGVHE0dMPAiuucoEs6r/ug8AucvUzWwMJRLIaPEOnuSh2Jtv+gdXDMbswWTVHGaw1IwYGcYdCxOL4uRlHjfG4+zzkVH0UfQHKYvtwXz7FNHgYE3+LpaVMovFt8v6nUX/TYpYgpOu6NMlkG3PXSqkovj11SAm3wHM5DLTu+HXJsHn/dY8uAUiitxLUP0x3aSq8VOcpyTDMr4Qui84R6Am3YUCkY+LBcaZzc37h2tR/cjwUHdSHmSVG4u0Nz5Rrcm6h+2hYYbq8eJrF/LjlQX2rS4JHguicwufKxsbJJBtuTEPLNtR8kKJkKFu3ePKXejTR9F92JWlKTWOQyuFROI4WcYFYTM5nxr00UxOhGN28qrJUiO7UKmnPMDWGt94v3Dwg69yMGwIt8DO+gjq2tkuytrSYEkat3usEEDOdG/wJv1KZcLBEshp96PoN3He2VfoUxa7B+DQ4iB+QcSViZsHxjTwbCBoiBXISfAB0D7nAHHDtBg50C4yDH77D+fcTzBd2BbIyHHgRt+wFynE9dOkP1hvs6y4l3voC36ve9H7tAsLCWRrzAVMYGZwgGIHMvy2hg0S7Xpn92EsE7E4i/j4U4SbL5yzkTlPqjZRkCvXCJTEusXGSn2tQKFLjRprDeJgA+XmPxANzsD41TTz/xqaiOTOJaXPT3PzrENdvpBANuN0HUx4MQP5iiGBb3MAtwmj/py9f/1oAcPjPOfrzGREDP3diDmI9HqaA8qdsxKkO1YC2yBxa74nyEJq0gQGdNAUfhCPa8VerHG2GRiROs8XHOutnmxEMyJvxhQSyBgkw1lIt0ogW0kQJcFjOcbBx1w+46fszdQIOR3TDB9mR/I9IToWFo20qRybSc8g6C2L94ucYz/OLGrZA8gg1kyjGR9EMkMsY0FberCI1wavkKLdmwHk+wsJZCuwYQdj3CUSyN33cibn2W9ymRjyJCfMcozTMZOu1x5rOWNz0Nc6TKSo4/qWE2SS1QCCZ+2+lJnGiAaBbHZKyzWQLtK0em+57hkAj7sx6vWFArJlQWVxmbkSyGLGQcw66kPP+KGjjUGM0261cvpd13ZPcVPajsYNjzSzTDCUsud5v/UeyMaLu91fiTa6UEC20jYZQDamSCCnLNaGtgcB2XGGV0MLOUHAncSizfUPkoFsIPv1RtpNo9tH4KFv8GpiqKAZZqh2EUGYJ1w4IBtVTCD7jDMkkCWQBdIQuwRE70u4qh4tFBOBEy0v31vgoTflGsi7Gbq+NjzMKgSQMdPGJg+7JzAzEtQlkIsbyFYBy1ddAPlhIZuNlWVkd8MfcwM/huuHUSzdj3tWOkUNfIvq21O1pnwDGSt5CEQBbZSRXRLINjnLowTquacnWGzCuvCiQH6NYqx5hetyKqn4ITVKZ5hxSB4W5BKvgYz1oXDhpVOy3I8xGyPVMosqUCSFWySQJZApVuw7HfRQu1jYi0LJNUZ6lqsnqvovGM74q7MPAuFYOwWd806AzJBQRKmttjQwUAJZAtlWV062VBLVjSc5AXIbJUl+nQDQrmVnmxiXuTZw+fVKPvcz7uxtQI4o2q9kPrIEMgXEhkP9+H+NzeQoMSCDCE0ByRfcFwmLlpc6hhUPnUVMje1nbRD8vFXViPYyIDfLCiESyHaE5Xiwn5kLY5eQ+gicT/sz3f1UMYCThXKJ4AJfDgv5R0zHeXn53snFrr2VLfcrBJBxUbHihSWQi9z9lCCPZ9FvXBdxP9Hyj7t4xe/MWsROalr59dUYaom6tRmbDRMMG0nEyvHd6hw8xum9AMjbMoM/JJAlkDNK9lRnEQySLHnLsV4nC47Tb/oqAfeT18XOROlz0VznHAF5s1n4XLCguQRycQLZajHcliWQ0RU1nwlkTIrAsp9uKyJgLeoCAXlpLpImkiVmTDB3k1kKWNEWYr0yoJkg0v/AaYqmBHLxARnbxQikMqLo/AB8vi9gxT6PmTTBKE/agVyX+TJV/bqCAFlAnM1liKbz7K18A1mbw1ZzKke4XOTvMMZ9VwI5zWccI9MFuO16rIkNHPcCgWPfjybIACqQsamV28QJbJtSACB/Bfr50L4EZLNLh8OCfVltHJyysxG14jznOdhj+3GKEK6SQE4SFgwQyGjalerdZBnEFgqAeQ6zGyPc4L9p4Ya8nGTR6ojekfZAoUv9OAdW5QiO1fsub6+nRTjvcJrTMbkFAvzGMgnk7rpbL3FBmSD3ZZT5GYy+Yyfg3w3IWNGDcfONbG4THG5yyfwAuUMkK6u3ARnda5x3tCSvEoADG0OaPaSGvRlpcySQzXpdNwpw1g3T55KDdhPH42SywLnrUBynV9Gkd6/bZhd2mPFSb8tLWxbBsMzeBmTrPl5j9Y/C1queXass0J9TwQRL4ZwrLlYHBnIbo6nGRcUOZGyoxu0OkSygdzaj1tdKASv2bVQgW1UE19PEJlaHCStLaXOOgbwRCxn0XSCzG5dh1hhvw/S0FI5ff0dk88Dii1bCCNNuQQsgKhYgW43c3hCwUjMbPdTPJ0ebTd/Y43Q0tpBTqAXqrX612ymGrzs4L2CcWHaQawPX6BxMTN6AjD2sRFrOYO9lLEGMkXNo7RalzGIGWMlTJMkDE1xoPvmwop9D39zFyjsVC5CBy94qIBZvjDaRgwWypK4R4MprUk3h7B8EFoQZsWTPma8Q6N7Y6b1ILVbNszcD2bIldOZO7dBX2+jl6wXPb7dqTz+c7OxhNrEXjbbrjJTqZcUMZCvwYweXG8fIOCGbSrL301qBjWEKsxsjupUoOlEHz4drxWBv82iBfszbPPoKkK2NblG+gJyWRZZr20WCnVyz5wMZi+MJ6MUtjkI742Q0q8F5KkMKS+SKtGp5imahZIVIYn1gsxlXNk23VOM+LwoU9CYgg9jsM9t05gnIIgs+S1fgW5ntcYoNyFc3kUEi1T7qm8mhTu8Fzr1HYIO4QazOr6pNpYRxrmBFCGEAAU4SJxrITt/6p2gfoL4G5DRbQme+gIzN93IUStvGS6wpBiBjJQ8vCujZ4i9BBsD57/GL3DvqrICZUrt1pNhp1rVmNLdK6mogbiv6XAzjs2lr+ipOCnYGQAA7aQfTF4Gc1JcrzsPEj3wA2Zq/ATyruaNrKfq6Wn/weKFn3cOBLFBcfkE2a6UuTs7h1cV20SolMNCKr34zc3dGoGPeMa8ROopiWOK22qediG6rPHDAXgdkcyGW6mXocsoHkFPdMWDTrRPtB8ygh3nidJFxZJ2Zgkhp8+KwnO5chjtrWVaDmyF7yWoeyy1gp9xWn2C1DKz9jEEHuHNj8oWXTd32BCB/nVBRcarpmlK0hVbFlnaXAHtJ5HpmUwHFuJ2R9WZbHhmLUDjpblgsQMb2qBhtZQOy9sYWcroXa8QSsZ+3u0Zdgpzl+aKsLhl/eI2qjTR9m77g2OQirRyBnFykTnaOLMVjTH+oDWFfokID2bZXL0gsEVX7Ce2+bcmhnx1j6FHEx2IPaJcA0ftty9uw3WpjuwrrnmN7XJG+wPTaboFBnPse6mZc1M9Z44p2EXWyXjJ99Rk9kR/F3sXAIT/EEj2z5pEyT9dFK+mPEV3oP8aGbkCLZ8ZJOf72fwD3URf7moi7AAAAAElFTkSuQmCC class=plx-logo></div><a target=_blank href="https://plu.mx/plum/a/?doi=10.1016/j.procs.2017.08.250&amp;theme=plum-sciencedirect-theme&amp;hideUsage=true" class=pps-seemore title="PlumX Metrics Detail Page">View details<svg fill=currentColor tabindex=-1 focusable=false width=16 height=16 viewBox="0 0 16 16" class=svg-arrow><path d="M16 4.452l-1.26-1.26L8 9.932l-6.74-6.74L0 4.452l8 8 8-8z"></path></svg></a></div></div></div></div></div></section></aside></div></div><div></div></div></div><footer role=contentinfo class="els-footer u-bg-white text-xs u-padding-s-hor u-padding-m-hor-from-sm u-padding-l-hor-from-md u-padding-l-ver u-margin-l-top u-margin-xl-top-from-sm u-margin-l-top-from-md"><div class="els-footer-elsevier u-margin-m-bottom u-margin-0-bottom-from-md u-margin-s-right u-margin-m-right-from-md u-margin-l-right-from-lg"><a aria-label="Elsevier home page (opens in a new tab)" href=https://www.elsevier.com/ target=_blank rel=nofollow><img class=footer-logo src=data:null;base64, alt="Elsevier logo with wordmark" height=64 width=58 loading=lazy></a></div><div class=els-footer-content><div class=u-remove-if-print><ul class="els-footer-links u-margin-xs-bottom" style=list-style:none><li><a class="anchor u-display-block u-clr-grey8 u-margin-s-bottom u-margin-0-bottom-from-sm u-margin-m-right-from-sm u-margin-l-right-from-md" href=https://www.elsevier.com/solutions/sciencedirect id=els-footer-about-science-direct target=_blank rel=nofollow><span class=anchor-text>About ScienceDirect</span></a><li><a class="anchor u-display-block u-clr-grey8 u-margin-s-bottom u-margin-0-bottom-from-sm u-margin-m-right-from-sm u-margin-l-right-from-md" href="https://www.sciencedirect.com/user/institution/login?targetURL=" id=els-footer-remote-access target=_blank rel=nofollow><span class=anchor-text>Remote access</span></a><li><a class="anchor u-display-block u-clr-grey8 u-margin-s-bottom u-margin-0-bottom-from-sm u-margin-m-right-from-sm u-margin-l-right-from-md" href=https://sd-cart.elsevier.com/? id=els-footer-shopping-cart target=_blank rel=nofollow><span class=anchor-text>Shopping cart</span></a><li><a class="anchor u-display-block u-clr-grey8 u-margin-s-bottom u-margin-0-bottom-from-sm u-margin-m-right-from-sm u-margin-l-right-from-md" href=http://elsmediakits.com/ id=els-footer-advertise target=_blank rel=nofollow><span class=anchor-text>Advertise</span></a><li><a class="anchor u-display-block u-clr-grey8 u-margin-s-bottom u-margin-0-bottom-from-sm u-margin-m-right-from-sm u-margin-l-right-from-md" href=https://service.elsevier.com/app/contact/supporthub/sciencedirect/ id=els-footer-contact-support target=_blank rel=nofollow><span class=anchor-text>Contact and support</span></a><li><a class="anchor u-display-block u-clr-grey8 u-margin-s-bottom u-margin-0-bottom-from-sm u-margin-m-right-from-sm u-margin-l-right-from-md" href=https://www.elsevier.com/legal/elsevier-website-terms-and-conditions id=els-footer-terms-condition target=_blank rel=nofollow><span class=anchor-text>Terms and conditions</span></a><li><a class="anchor u-display-block u-clr-grey8 u-margin-s-bottom u-margin-0-bottom-from-sm u-margin-m-right-from-sm u-margin-l-right-from-md" href=https://www.elsevier.com/legal/privacy-policy id=els-footer-privacy-policy target=_blank rel=nofollow><span class=anchor-text>Privacy policy</span></a></ul></div><p id=els-footer-cookie-message class=u-remove-if-print>We use cookies to help provide and enhance our service and tailor content and ads. By continuing you agree to the <a class="anchor u-clr-grey8 u-margin-0-right" href=https://www.sciencedirect.com/legal/use-of-cookies target=_blank rel=nofollow><span class=anchor-text><strong>use of cookies</strong></span></a>.<p id=els-footer-copyright>Copyright © 2022 Elsevier B.V. or its licensors or contributors. <span class=u-remove-if-print>ScienceDirect® is a registered trademark of Elsevier B.V.</span><p class="u-remove-if-not-print sf-hidden">ScienceDirect® is a registered trademark of Elsevier B.V.</p></div><div class="els-footer-relx u-margin-0-top u-margin-m-top-from-xs u-margin-0-top-from-md"><a aria-label="RELX home page (opens in a new tab)" id=els-footer-relx href=https://www.relx.com/ target=_blank rel=nofollow><img loading=lazy src=data:null;base64, width=93 height=20 alt="RELX group home page"></a></div></footer></div></section></div></div></div>
<div id=UMS_TOOLTIP style=position:absolute;cursor:pointer;z-index:2147483647;background:transparent;top:-100000px;left:-100000px></div><div class=js-react-modal></div><div class=js-react-modal></div><div class=js-react-modal></div><div class=js-react-modal></div><div class=js-react-modal></div><div class=js-react-modal></div><div id=gs-casa-r><div id=gs-casa-c><div id=gs-casa-b><a id=gs-casa-f href="https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S1877050917316599/pdf%3Fmd5%3Debc69bd9b22743849a3a3f3730ad326a%26pid%3D1-s2.0-S1877050917316599-main.pdf%26_valck%3D1&amp;hl=en&amp;sa=T&amp;oi=ucasa&amp;ct=ufr&amp;ei=k-omY7LDN7aQ6rQP-NO84AU&amp;scisig=AAGBfm0np90i-oI_pPHd_yR8-uNo21ujow">PDF</a><a id=gs-casa-h target=_blank href=https://scholar.google.com/scholar/help.html#access>Help</a></div></div></div><button aria-label=Feedback type=button id=_pendo-badge_9BcFvkCLLiElWp6hocDK3ZG6Z4E data-layout=badgeBlank class="_pendo-badge _pendo-badge_" style="z-index:19000;margin:0px;line-height:1;font-size:0px;background:rgba(255,255,255,0);padding:0px;height:32px;width:128px;box-shadow:rgb(136,136,136) 0px 0px 0px 0px;border:0px;float:none;vertical-align:baseline;cursor:pointer;position:absolute;top:6221px;left:1423px"><img id=pendo-image-badge-c2b2bcc0 src=data:image/svg+xml;base64,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 data-_pendo-image-1 class="_pendo-image _pendo-badge-image" style="display:block;height:32px;width:128px;padding:0px;margin:0px;line-height:1;border:none;box-shadow:rgb(136,136,136) 0px 0px 0px 0px;float:none;vertical-align:baseline"></button><umsdataelement id=UMSSendDataEventElement></umsdataelement><div id=tmtoolbar_manual_rating_injected style=display:none>init</div><script data-template-shadow-root>(()=>{document.currentScript.remove();processNode(document);function processNode(node){node.querySelectorAll("template[shadowmode]").forEach(element=>{let shadowRoot = element.parentElement.shadowRoot;if (!shadowRoot) {try {shadowRoot=element.parentElement.attachShadow({mode:element.getAttribute("shadowmode"),delegatesFocus:Boolean(element.getAttribute("delegatesfocus"))});shadowRoot.innerHTML=element.innerHTML;element.remove()} catch (error) {} if (shadowRoot) {processNode(shadowRoot)}}})}})()</script>